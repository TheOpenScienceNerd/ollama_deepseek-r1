{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4a42a8-71b3-437f-b05f-19e99e24d521",
   "metadata": {},
   "source": [
    "# Interact with Deepseek-R1 via Ollama Python\n",
    "\n",
    "In this notebook we will learn how to\n",
    "\n",
    "1. List open models installed on your local machine\n",
    "2. Stream responses from deepseek-r1\n",
    "\n",
    "> Ollama python package can be installed from [PyPI](https://pypi.org/project/ollama/). I have provided a [conda environment](./environment.yml) file that will install it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e204f-0c15-4d70-845d-3ddff4afda2f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437032e-5656-491b-a0cd-9c1c07fb4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from ollama import chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495cbcd-7474-4a56-ae4a-fa7fcddaba84",
   "metadata": {},
   "source": [
    "## Open models installed on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c278f1e-9dae-4731-a84e-0571a292dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def installed_models():\n",
    "    '''\n",
    "    Iterate through ollama models and return names as list\n",
    "    '''\n",
    "    return [md.model for md in ollama.list().models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff5930-932a-43b1-ae73-70533fe32104",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_models = installed_models()\n",
    "local_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dd7a4e-4786-48b8-9f9f-cb2cf8d12523",
   "metadata": {},
   "source": [
    "## Stream Chat Responses from a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d48319e-fe11-4ab1-a2b9-68079d4bd217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream(model_name: str, prompt_msg: str):\n",
    "    '''get a streaming chat from a model\n",
    "    '''\n",
    "    stream = chat(\n",
    "        model=model_name,\n",
    "        messages=[{'role': 'user', 'content': prompt_msg}],\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b6c78-f0e8-4b5c-b8a3-56bf931cece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"\n",
    "Given five positive integers in a list, find the minimum and maximum values that\n",
    "can be calculated by summing exactly four of the five integers. \n",
    "Print the respective minimum and maximum values. \n",
    "Code the solution in Python as a python function that accepts a Python list \n",
    "as a parameter.\n",
    "\n",
    "Example\n",
    "\n",
    "input  = [9, 3, 5, 7, 1]\n",
    "Output = 16, 24\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c1142-8200-4509-9c8e-1bb3fba2adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 1.5b parameter model\n",
    "stream = get_stream(local_models[0], prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a14552-b4e8-492a-b058-d526dc16860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_fname = 'response_1.txt'\n",
    "with open(response_fname, 'w') as writer:\n",
    "    for chunk in stream:\n",
    "      print(chunk['message']['content'], end='', flush=True)\n",
    "      writer.write(chunk['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e0914-59c3-4200-9dd6-026549c22b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
